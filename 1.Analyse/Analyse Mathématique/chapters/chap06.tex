\chapter{Definite Integral} % 定积分
\section{Riemann Integral}
\begin{leftbarTitle}{Riemann Integral}\end{leftbarTitle}
\begin{definition}{Riemann Integral}
    Let \( f(x) \) be a bounded function defined on \( [a, b] \). 
    Take any set of division points \( \{x_i\}_{i=0}^n \) on \( [a, b] \) 
    to form a partition \( P: a = x_0 < x_1 < \dots < x_n = b \), 
    and choose arbitrary points \( \xi_i \in [x_{i-1}, x_i] \). 
    Denote the length of the sub-interval \( [x_{i-1}, x_i] \) 
    as \( \Delta x_i = x_i - x_{i-1} \), 
    and let \( \lambda = \max\limits_{1 \leqslant i \leqslant n} (\Delta x_i) \). 
    If the limit  
    \[
    \lim_{\lambda \to 0} \sum_{i=1}^n f(\xi_i) \Delta x_i
    \]  
    exists as \( \lambda \to 0 \), 
    and the limit is independent of the partition \( P \) and 
    the choice of \( \xi_i \), 
    then \( f(x) \) is said to be \textbf{Riemann integrable} on \( [a, b] \).

    The summation  
    \[
    S_n = \sum_{i=1}^n f(\xi_i) \Delta x_i
    \]  
    is called the Riemann sum, 
    and its limit \( I \) is called the definite integral of \( f(x) \) on \( [a, b] \), 
    denoted as:  
    \[
    I = \int_a^b f(x) \, \mathrm{d}x,
    \]  
    where \( a \) and \( b \) are called the lower and upper limits of the definite integral, respectively.

    Alternatively, it can also be expressed as:  
    \[
    \exists I, \forall \varepsilon > 0, \exists \delta > 0, \text{s.t.} \forall P
    (\lambda = \max\limits_{1 \leqslant i \leqslant n} (\Delta x_i) < \delta), \forall \{\xi_i\}:
    \left| \sum_{i=1}^n f(\xi_i) \Delta x_i - I \right| < \varepsilon.
    \] 
    Then \( f(x) \) is said to be Riemann integrable on \( [a, b] \), 
    and \( I \) is the definite integral of \( f(x) \) on \( [a, b] \).
\end{definition}

\begin{remark}
    Partition \(\to\) Intermediate points \(\to\) Summation \(\to\) Take the limit.
\end{remark}

\begin{leftbarTitle}{Darboux Sum}\end{leftbarTitle}
\begin{definition}{Darboux Sum}
    Let the supremum and infimum of \( f(x) \) on \( [a, b] \) be \( M \) and \( m \), respectively. 
    Clearly, \( m \leqslant f(x) \leqslant M \).
    Let the supremum and infimum of \( f(x) \) on \( [x_{i-1}, x_i] \) 
    be \( M_i \) and \( m_i \) (\( i = 1, 2, \dots, n \)), respectively, i.e.,  
    \[
    M_i = \sup\{ f(x) \mid x \in [x_{i-1}, x_i] \}, \quad m_i = \inf\{ f(x) \mid x \in [x_{i-1}, x_i] \}.
    \]

    After fixing the partition \( P \), define the sums:  
    \[
    \bar{S}(P) = \sum_{i=1}^n M_i \Delta x_i, \quad \underline{S}(P) = \sum_{i=1}^n m_i \Delta x_i,
    \]  
    which are called the Darboux upper sum and Darboux lower sum corresponding to the partition \( P \), respectively.
\end{definition}

\begin{property}
    \begin{enumerate}
    \item \( \underline{S}(P) \leqslant \sum_{i=1}^n f(\xi_i) \Delta x_i \leqslant \bar{S}(P) \).
    \item If a new partition is formed by adding division points to the original partition, 
        the upper sum does not increase, and the lower sum does not decrease.
    \item Let \( \boldsymbol{\bar{S}} \) denote the set of Darboux upper sums 
        and \( \boldsymbol{\underline{S}} \) denote the set of Darboux lower sums. 
        For any \( \bar{S}(P_1) \in \boldsymbol{\bar{S}}, \underline{S}(P_2) \in \boldsymbol{\underline{S}} \), 
        it always holds that:  
        \[
        m(b-a) \leqslant \underline{S}(P_2) \leqslant \bar{S}(P_1) \leqslant M(b-a).
        \]
    \item Let \( L = \inf\{ \bar{S}(P) \mid \bar{S}(P) \in \boldsymbol{\bar{S}} \}, l = \sup\{ \underline{S}(P) \mid \underline{S}(P) \in \boldsymbol{\underline{S}} \} \), which are called the upper integral and lower integral, respectively. It always holds that: \( l \leqslant L \).
    \item \textbf{Darboux's Theorem}: For any \( f(x) \in B[a, b] \), it always holds that:  
        \[
        \lim_{\lambda \to 0} \bar{S}(P) = L, \quad \lim_{\lambda \to 0} \underline{S}(P) = l.
        \]
\end{enumerate}
\end{property}


\begin{leftbarTitle}{Riemann-Stieltjes Integral}\end{leftbarTitle}
\begin{definition}{Riemann-Stieltjes Integral}
    Let \( \alpha \) be a bounded, monotonically increasing function on \( [a, b] \). 
    For every partition \( P \) of \( [a, b] \), let \( \Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1}) \) 
    (clearly \( \Delta \alpha_i \geqslant 0 \)).
    For a bounded real function \( f(x) \) on \( [a, b] \), define the Stieltjes upper sum and lower sum as:  
    \[
    \bar{S}(P, \alpha) = \sum_{i=1}^n M_i \Delta \alpha_i, \quad \underline{S}(P, \alpha) = \sum_{i=1}^n m_i \Delta \alpha_i,
    \]  
    and define the upper and lower integrals as:  
    \[
    L = \inf\{ \bar{S}(P, \alpha) \mid \bar{S}(P, \alpha) \in \boldsymbol{\bar{S}} \}, \quad l = \sup\{ \underline{S}(P, \alpha) \mid \underline{S}(P, \alpha) \in \boldsymbol{\underline{S}} \},
    \]  
    where \( \boldsymbol{\bar{S}, \underline{S}} \) are the sets of Stieltjes upper and lower sums respectively.

    If \( L = l \), then:  
    \[
    \int_{a}^b f(x) \, \mathrm{d}\alpha(x) = L = l,
    \]  
    and \( f(x) \) is said to be \textbf{Riemann-Stieltjes integrable} on \( [a, b] \) with respect to \( \alpha \), 
    or simply Stieltjes integrable.
\end{definition}

When \( \alpha(x) = x \), this reduces to the Riemann integral. 
However, in general, \( \alpha(x) \) does not even need to be continuous.

The properties of Darboux sums also apply to Stieltjes sums.

\section{Integrability Criteria}
\begin{leftbarTitle}{Common Integrability Criteria}\end{leftbarTitle}
\begin{theorem}{Integrability Criterion}
    A bounded function \( f(x) \) is Riemann integrable on \( [a, b] \) if and only if:
    \begin{itemize}
        \item  The upper and lower integrals are equal, i.e.,
            \[
            \forall P(\lambda = \max_{1 \leqslant i \leqslant n}(\Delta x_{i}) < \delta): 
                \lim_{\lambda \to 0} \bar{S}(P) = L = l = \lim_{\lambda \to 0} \underline{S}(P).
            \]
        \item  Let \( \omega_{i} = M_{i} - m_{i} \) be the oscillation of \( f(x) \) on \( [x_{i-1}, x_{i}] \). Then:
            The limit of the sum of oscillations is zero, i.e.,
            \[
            \forall P(\lambda = \max_{1 \leqslant i \leqslant n}(\Delta x_{i}) < \delta): 
            \lim_{\lambda \to 0} \sum_{i=1}^{n} \omega_{i} \Delta x_{i} = 0.
            \]
            \begin{description}
                \item [Corollary 1] Continuous functions on closed intervals are necessarily integrable.
                \item [Corollary 2] Monotonic functions on closed intervals are necessarily integrable.
            \end{description}
        \item For all \( \varepsilon > 0 \), there exists a partition \( P \) such that:
            \[
            \sum\limits_{i=1}^{n} \omega_{i} \Delta x_{i} < \varepsilon.
            \]
            \begin{description}
                \item [Corollary 1] The total length of intervals where oscillation \( \omega \) 
                    cannot be arbitrarily small can be made arbitrarily small, i.e.,
                    \[
                    \forall \varepsilon, \eta > 0, \exists P,\text{s.t.} \sum_{\omega\geqslant \eta} \Delta x_{i} < \varepsilon.
                    \]
                \item [Corollary 2] Bounded functions with only finitely many discontinuities on closed intervals 
                    are necessarily integrable.
            \end{description}
    \end{itemize}
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{leftbarTitle}{Lesbesgue's Theorem}\end{leftbarTitle}
\begin{definition}{Null Set}
    A set \( E \subset \mathbb{R} \) is called a \textbf{null set} (or measure zero set) 
    if for any \( \varepsilon > 0 \), there exists a countable collection of open intervals 
    \( \{ I_{n}|n \in \mathbb{N}^{*} \} \) such that:
    \[
    E \subset \bigcup_{i=1}^{\infty} I_{n} \quad \text{and} \quad \sum_{i=1}^{\infty} |I_{n}| < \varepsilon.
    \]
\end{definition}
If some property holds for all \( x \in A \) except for a null set \( E \subset A \),
we say that the property holds \textbf{almost everywhere} on \( A \).

\begin{lemma}
    \begin{enumerate}
        \item Let \( \omega \) be the oscillation of bounded function \( f(x) \) on \( [a, b] \), then:
            \[
            \omega = \sup \{ f(y_{1}) - f(y_{0}) \mid y_{0}, y_{1} \in [a, b] \}  .
            \]
        \item \(f(x)\) is continuous at point \( x_{0} \) if and only if 
            the oscillation of \( f(x) \) at \( x_{0} \) is zero, i.e., \( \omega_{f}(x_{0}) = 0 \).
        \item Let \(D(f)\) be the set of discontinuities of bounded function \( f(x) \) on \( [a, b] \). 
            For \(\delta > 0\), denote \(D_{\delta}= \{ x \in [a,b] \mid \omega_{f}(x) \geqslant \delta \}\).
            Then 
            \[
            D(f) = \bigcup_{n=1}^{\infty} D_{\frac{1}{n}}.
            \]
        \item If there exists a series of open intervals \( (\alpha_{j}, \beta_{j}) \) (\( j = 1, 2, \cdots \)) 
            such that \(D(f) \subset \bigcup_{j=1}^{\infty} (\alpha_{j}, \beta_{j})\), 
            and let \(K = [a,b]\setminus \bigcup_{j=1}^{\infty} (\alpha_{j}, \beta_{j})\).
            Then:
            \[
            \forall \varepsilon > 0, \exists \delta > 0, \text{s.t.} \forall x \in K, y \in [a,b] (|x - y| < \delta):
            |f(x) - f(y)| < \varepsilon.
            \]
    \end{enumerate}
\end{lemma}

\begin{theorem}{Lesbesgue's Theorem}
    Let \(f(x)\in B[a,b]\), then \(f(x)\) is Riemann integrable on \([a,b]\) if and only if 
    \(f(x)\) is continuous almost everywhere on \([a,b]\).
\end{theorem}


\section{Properties of Definite Integrals}
\begin{leftbarTitle}{Properties of Riemann Integrals}\end{leftbarTitle}
\begin{property}
    \begin{description}
        \item [Linearity] Let \( f(x), g(x) \in R[a, b] \), and \( k_1, k_2 \) are constants. 
            Then the function \( k_1 f(x) + k_2 g(x) \in R[a, b] \), and:
            \[
            \int_{a}^b [k_1 f(x) + k_2 g(x)] \mathrm{d}x = k_1 \int_{a}^b f(x) \mathrm{d}x + k_2 \int_{a}^b g(x) \mathrm{d}x.
            \]
        \item[Multiplicative Integrability] Let \( f(x), g(x) \in R[a, b] \), and \( k_1, k_2 \). 
            Then \( f(x) \cdot g(x) \in R[a, b] \). In general, 
            \[
            \int_{a}^b f(x) g(x) \mathrm{d}x \neq \left( \int_{a}^b f(x) \mathrm{d}x \right) \cdot \left( \int_{a}^b g(x) \mathrm{d}x \right).
            \]
        \item[Monotonicity] Let \( f(x), g(x) \in R[a, b] \), 
            and \( f(x) \geqslant g(x) \) (or \( f(x) > g(x) \)) on \( [a, b] \). Then:
            \[
            \int_{a}^b f(x) \mathrm{d}x \geqslant \int_{a}^b g(x) \mathrm{d}x \quad \left( \int_{a}^b f(x) \mathrm{d}x > \int_{a}^b g(x) \mathrm{d}x \right).
            \]
            \begin{description}
                \item[Corollary 1] If \( f(x) \in C[a, b], f(x) \geqslant 0, f(x) \not\equiv 0 \), then:
                    \[
                    \int_{a}^{b} f(x) \, \mathrm{d}x > 0.
                    \]
                \item[Corollary 2] If \( f(x) \in R[a, b], f(x) > 0 \), then:
                    \[
                    \int_{a}^{b} f(x) \, \mathrm{d}x > 0.
                    \]
            \end{description}
        \item[Absolute Value Integrability] Let \( f(x) \in R[a, b] \). Then \( |f(x)| \in R[a, b] \), and:
            \[
            \left| \int_{a}^b f(x) \mathrm{d}x \right| \leqslant \int_{a}^b |f(x)| \mathrm{d}x.
            \]
            The inverse statement of this property is not true.
        \item[Additivity Over Intervals] Let \( f(x) \in R[a, b] \). 
            For any point \( c \in [a, b] \), \( f(x) \) is integrable on \( [a, b] \) and \( [c, d] \). 
            Conversely, if \( f \in R[a, c] \cup [c, b] \), then \( f(x) \) is integrable on \( [a, b] \), and:
            \[
            \int_{a}^b f(x) \mathrm{d}x = \int_{a}^c f(x) \mathrm{d}x + \int_{c}^b f(x) \mathrm{d}x.
            \]
    \end{description}
\end{property}

\begin{theorem}{Integral Mean Value Theorem}
    \begin{description}
        \item[First Integral Mean Value Theorem ] Let \( f(x), g(x) \in R[a, b] \), 
            and \( g(x) \) does not change sign on \( [a, b] \). Then there exists \( \eta \in [m, M] \) such that:
            \[
            \int_{a}^b f(x)g(x) \mathrm{d}x = \eta \int_{a}^b g(x) \mathrm{d}x,
            \]
            where \( m, M \) represent the infimum and supremum of \( f(x) \) on \( [a, b] \), respectively.

            In particular, if \( f(x) \in C[a, b] \), then there exists \( \xi \in [a, b] \) such that:
            \[
            \int_{a}^b f(x)g(x) \mathrm{d}x = f(\xi) \int_{a}^b g(x) \mathrm{d}x.
            \]

            A special case arises when \( f(x) \in C[a, b] \) and \( g(x) \equiv 1 \), then:
            \[
            \int_{a}^{b} f(x)g(x) \mathrm{d}x = f(\xi) \int_{a}^{b} g(x) \mathrm{d}x.
            \]
            \begin{description}
                \item[Corollary] If \( f(x) \in C[a, b] \), then there exists \( \xi \in (a, b) \) such that:
                    \[
                    \int_{a}^b f(x)g(x) \mathrm{d}x = f(\xi) \int_{a}^b g(x) \mathrm{d}x.
                    \]
            \end{description} 
        \item[Second Integral Mean Value Theorem (Bonnet Formula)] Let \( f(x) \in R[a, b] \),
            \begin{itemize}
            \item If \( g(x) \) is decreasing on \( [a, b] \) and \( g(x) \geqslant 0 \) (\( x \in [a, b] \)):
            \[
            \exists \xi \in [a, b]: \quad \int_{a}^{b} f(x)g(x) \mathrm{d}x = g(a)\int_{a}^{\xi} f(x) \mathrm{d}x.
            \]
            \item If \( g(x) \) is increasing on \( [a, b] \) and \( g(x) \geqslant 0 \) (\( x \in [a, b] \)):
            \[
            \exists \eta \in [a, b]: \quad \int_{a}^{b} f(x)g(x) \mathrm{d}x = g(b)\int_{\eta}^{b} f(x) \mathrm{d}x.
            \]
            \end{itemize}
            The general form is:
            Let \( f(x) \in R[a, b] \), and \( g(x) \) be a monotonic function. Then:
            \[
            \exists \xi \in [a, b], \quad \int_{a}^{b} f(x)g(x) \mathrm{d}x = g(a)\int_{a}^{\xi} f(x) \mathrm{d}x + g(b)\int_{\xi}^{b} f(x) \mathrm{d}x.
            \]
    \end{description}
\end{theorem}

\begin{note}
    For the first integral mean value theorem, 
    \begin{itemize}
        \item If \( f(x) \in C[a, b] \) is replaced with \( f(x) \in R[a, b] \), the conclusion does not hold.
        \item If \( f(x) \in R[a, b] \) and \( \int f(x)\mathrm{d}x \) exists, the conclusion holds.
    \end{itemize}
\end{note}


\begin{leftbarTitle}{Integrability of Composite Functions}\end{leftbarTitle}

\begin{description}
    \item [Outer Continuity, Inner Integrability] Let \( f(x) \in R[a, b] \), \( A \leqslant f(x) \leqslant B \), 
        and \( g(u) \in C[A, B] \). Then the composite function \( g(f(x)) \in R[a, b] \).
    \item [Outer Integrability, Inner Continuity] In this case, the composite function may not be integrable.

    \item [Both Inner and Outer Integrability] In this case, the composite function may not be integrable. 
        In fact, even if both the inner and outer functions are not integrable, the composite function may still be integrable.
\end{description}



\section{Fundamental Theorem of Calculus}
\begin{leftbarTitle}{Newton-Leibniz Formula}\end{leftbarTitle}
\begin{definition}{Variable Limit Integrals}
    Let \( f(x) \in R[a, b] \). Define:
    \[
    F(x) = \int_{a}^{x} f(t) \, \mathrm{d}t \quad \text{and} \quad F(x) = \int_{x}^{b} f(t) \, \mathrm{d}t,
    \]
    which are referred to as the variable upper limit integral and variable lower limit integral, respectively.
\end{definition}

\begin{property}
    \begin{description}
        \item [Continuity of Antiderivative]  \( F(x) \in C[a, b] \) (The variable upper limit integral satisfies the 
            Lipschitz condition and is uniformly continuous on the closed interval).
        \item [Fundamental Theorem of Calculus] Let \( x_0 \in [a, b] \) be a point where \( f(x) \) is continuous. Then:
            \[
            F'(x_0) = f(x_0).
            \]
        \item [Existence of Antiderivatives] If \( f(x) \in C[a, b] \), then \( F(x) \in D[a, b] \) and \( F'(x) = f(x) \).
        \item [Rule of Derivation] If \( F(x) = \int_{u(x)}^{v(x)} f(t) \, \mathrm{d}t \), then:
            \[
            F'(x) = f(v(x))v'(x) - f(u(x))u'(x).
            \]
            In fact, the formula is the simplified version of the \textbf{Leibniz's law}.
    \end{description}
\end{property}


\begin{remark}
        Differentiation can reduce the smoothness of functions (the original function may be differentiable, 
        while the derivative may have second-type discontinuities), whereas integration can improve smoothness.
\end{remark}

\begin{theorem}{Newton-Leibniz Formula}
    Let \( f(x) \in C[a, b] \), and \( F(x) \) be an antiderivative of \( f(x) \) on \( [a, b] \). Then:
    \[
    \int_{a}^{b} f(x) \, \mathrm{d}x = F(b) - F(a).
    \]

    \textbf{Generalized Newton-Leibniz Formula}
    Let \( f(x) \in R[a, b] \), \( F(x) \in C[a, b] \), and \( F'(x) = f(x) \) holds except for finitely many points. 
    Then:
    \[
    \int_{a}^{b} f(x) \, \mathrm{d}x = F(b) - F(a).
    \]
\end{theorem}



\begin{leftbarTitle}{Common Questions concerning Integrals}\end{leftbarTitle}

\section{Calculation of Definite Integrals}



\begin{example}
    Prove the ignition formula (Wallis formula) with recursion method:
    \[
    \int_{0}^{\frac{\pi}{2}} \sin^{n} x \, \mathrm{d}x 
    = \int_{0}^{\frac{\pi}{2}} \cos^{n} x \, \mathrm{d}x
    = \begin{cases}
    \frac{(n-1)!!}{n!!} \cdot \frac{\pi}{2}, & n \text{ is even}; \\
    \frac{(n-1)!!}{n!!}, & n \text{ is odd}.
    \end{cases}
    \]
\end{example}


\section{Integral Inequalities}

\begin{theorem}{Integral Inequalities}
    \begin{description}
        \item[Hadamard Inequality] Let \( f(x) \) be a convex function on \( (a, b) \). 
            Then for any pair \( x_1, x_2 \in (a, b) \) with \( x_1 < x_2 \), we have:
            \[
            f\left( \frac{x_1 + x_2}{2} \right) \leqslant \frac{1}{x_2 - x_1} \int_{x_1}^{x_2} f(t) \, \mathrm{d}t \leqslant \frac{f(x_1) + f(x_2)}{2}.
            \]

        \item[Schwarz Inequality] Let \( f(x), g(x) \in R[a, b] \). Then:
            \[
            \left( \int_{a}^{b} f(x)g(x) \, \mathrm{d}x \right)^2 \leqslant \int_{a}^{b} f^2(x) \, \mathrm{d}x \int_{a}^{b} g^2(x) \, \mathrm{d}x.
            \]

        \item[Hölder Inequality] Let \( f(x), g(x) \in R[a, b] \), and \( p, q \) are conjugate numbers 
            (i.e., \( p > 0, q > 0, \frac{1}{p} + \frac{1}{q} = 1 \)). Then:
            \[
            \int_{a}^{b} |f(x)g(x)| \, \mathrm{d}x \leqslant \left( \int_{a}^{b} |f(x)|^p \, \mathrm{d}x \right)^{\frac{1}{p}} \left( \int_{a}^{b} |g(x)|^q \, \mathrm{d}x \right)^{\frac{1}{q}}.
            \]

        \item[Young Inequality] Let \( y = f(x) \in C[0, +\infty) \), strictly increasing, 
            and \( f(0) = 0 \). Denote its inverse function as \( x = f^{-1}(y) \). Then:
            \[
            \int_{0}^{a} f(x) \, \mathrm{d}x + \int_{0}^{b} f^{-1}(y) \, \mathrm{d}y \geqslant ab \quad (a > 0, b > 0).
            \]

        \item[Minkowski Inequality] Let \( f(x), g(x) \in R[a, b] \). Then:
            \[
            \left\{ \int_{a}^{b} [f(x) + g(x)]^2 \, \mathrm{d}x \right\}^{\frac{1}{2}} \leqslant \left[ \int_{a}^{b} f^2(x) \, \mathrm{d}x \right]^{\frac{1}{2}} + \left[ \int_{a}^{b} g^2(x) \, \mathrm{d}x \right]^{\frac{1}{2}}.
            \]

        \item[Чебышёв Inequality] Let \( f(x), g(x) \) be similarly ordered functions, 
                i.e., \( \forall x_1, x_2: (f(x_1) - f(x_2))(g(x_1) - g(x_2)) \geqslant 0 \). Then:
                \[
                \int_{a}^{b} f(x) \, \mathrm{d}x \int_{a}^{b} g(x) \, \mathrm{d}x \leqslant (b - a) \int_{a}^{b} f(x)g(x) \, \mathrm{d}x.
                \]

            \textbf{Discrete Form} Let sequences \( \{a_n\}, \{b_n\} \) be similarly ordered, 
                i.e., \( \forall i, j: (a_i - a_j)(b_i - b_j) \geqslant 0 \). Then:
                \[
                \left( \sum\limits_{i=1}^{n} a_i \right) \left( \sum\limits_{i=1}^{n} b_i \right) \leqslant n \sum\limits_{i=1}^{n} a_i b_i.
                \]
            If the sequences are oppositely ordered, the inequality reverses.
    \end{description}
\end{theorem}


\begin{example}
    Let \(f(t)\) be convex on \([0,1]\), prove that:
    \[
    \int_{0}^{1} t(1-t)f(t) \, \mathrm{d}t \leqslant \frac{1}{3}\int_{0}^{1} \left( t^{3}+(1-t)^{3} \right)  f(t) \, \mathrm{d}t.
    \]
\end{example}
\begin{proof}
    Since \(f(t)\) is convex on \([0,1]\), for any \(t \in (0,1)\), we have:
    \[
    t = (1-t)(tx)+t(1-x+tx),
    \]
    then 
    \[
    f(t) \leqslant (1-t)f(tx) + t f(1 - x + tx).
    \]
    Integrating both sides from \(0\) to \(1\) with respect to \(x\), we get:
    \[
    f(t) \leqslant (1-t) \int_{0}^{1} f(tx) \, \mathrm{d}x + t \int_{0}^{1} f(1 - x + tx) \, \mathrm{d}x
    = \frac{1-t}{t}\int_{0}^{t}f(x)\mathrm{d}x+\frac{t}{1-t}\int_{t}^{1}f(x)\mathrm{d}x.
    \]
    Multiplying both sides by \(t(1-t)\) and integrating from \(0\) to \(1\) with respect to \(t\), we have:
    \[
    \int_{0}^{1} t(1-t) f(t) \, \mathrm{d}t \leqslant 
    \int_{0}^{1} \left[(1-t)^{2} \int_{0}^{t} f(x) \, \mathrm{d}x\right] \, \mathrm{d}t 
    + \int_{0}^{1} t^{2} \left[\int_{t}^{1} f(x) \, \mathrm{d}x\right] \, \mathrm{d}t.
    \]
    Change the order of integration in the right side:
    \[
    \int_{0}^{1} \left[(1-t)^{2} \int_{0}^{t} f(x) \, \mathrm{d}x\right] \, \mathrm{d}t 
    + \int_{0}^{1} t^{2} \left[\int_{t}^{1} f(x) \, \mathrm{d}x\right] \, \mathrm{d}t
    = \frac{1}{3}\int_{0}^{1} \left( t^{3}+(1-t)^{3} \right)  f(t) \, \mathrm{d}t.
    \]
    Thus, the desired inequality is proven.
\end{proof}

\section{Applications of Definite Integrals}


\begin{leftbarTitle}{Polar Coordinate System}\end{leftbarTitle}
\footnotesize
\begin{tabular}{|p{2cm}|c|c|c|}
\hline
Category & Explicit Cartesian Equation & Parametric Cartesian Equation & Polar Equation \\ 

\hline
\centering {\small Equation} &
\( y = f(x), x \in [a, b] \) &
\( 
\begin{cases}
x = x(t), t \in [T_1, T_2], \\
y = y(t),
\end{cases}
\) &
\( r = r(\theta), \theta \in [\alpha, \beta] \) \\ 

\hline
\centering {\small Area of Plane Shape} &
\( \int_{a}^b f(x) \, \mathrm{d}x \) &
\( \int_{T_1}^{T_2} |y(t)x'(t)| \, \mathrm{d}t \) &
\( \frac{1}{2} \int_{\alpha}^{\beta} r^2(\theta) \, \mathrm{d}\theta \) \\ 

\hline
\centering {\small Infinitesimal Arc Length} &
\( \mathrm{d}l = \sqrt{1 + [f'(x)]^2} \, \mathrm{d}x \) &
\( \mathrm{d}l = \sqrt{[x'(t)]^2 + [y'(t)]^2} \, \mathrm{d}t \) &
\( \mathrm{d}l = \sqrt{r^2(\theta) + r'^2(\theta)} \, \mathrm{d}\theta \) \\ 

\hline
\centering {\small Curve Length} &
\( \int_{a}^b \sqrt{1 + [f'(x)]^2} \, \mathrm{d}x \) &
\( \int_{T_1}^{T_2} \sqrt{[x'(t)]^2 + [y'(t)]^2} \, \mathrm{d}t \) &
\( \int_{\alpha}^{\beta} \sqrt{r^2(\theta) + r'^2(\theta)} \, \mathrm{d}\theta \) \\ 

\hline
\centering {\small Volume of Solid of Revolution} &
\( \pi \int_{a}^b [f(x)]^2 \, \mathrm{d}x \) &
\( \pi \int_{T_1}^{T_2} y^2(t)x'(t) \, \mathrm{d}t \) &
\( \frac{2}{3} \pi \int_{\alpha}^{\beta} r^3(\theta) \sin\theta \, \mathrm{d}\theta \) \\ 

\hline
\centering {\small Surface Area of Solid of Revolution} &
\( 2\pi \int_{a}^b f(x) \sqrt{1 + [f'(x)]^2} \, \mathrm{d}x \) &
\( 2\pi \int_{T_1}^{T_2} y(t) \sqrt{[x'(t)]^2 + [y'(t)]^2} \, \mathrm{d}t \) &
\( 2\pi \int_{\alpha}^{\beta} r(\theta)\sin\theta \sqrt{r^2(\theta) + r'^2(\theta)} \, \mathrm{d}\theta \) \\ \hline
\end{tabular}
\normalsize