
\chapter{First Order Equations} % 一阶方程
\section{Exact Equations}
\begin{definition}{Exact Equations}
An equation of the form
\begin{equation}\label{eq:symmetric form}
    M(x,y) \, \mathrm{d}x + N(x,y) \, \mathrm{d}y = 0
\end{equation}
is called the symmetric form (or differential form) of a first-order differential equation.

If there exists a continuously differentiable function $U(x,y)$ such that
\[
\mathrm{d}U(x,y) = M(x,y) \, \mathrm{d}x + N(x,y) \, \mathrm{d}y,
\]
then equation~\eqref{eq:symmetric form} is said to be an \textbf{exact equation} or a \textbf{total differential equation}.

It follows that, when equation~\eqref{eq:symmetric form} is exact, it can be rewritten as
\[
\mathrm{d}(U(x,y)) = 0,
\]
which implies
\begin{equation}\label{general integral}
    U(x,y) = c,
\end{equation}
where $c$ is an arbitrary constant. Equation~\eqref{general integral} is called the \textbf{general integral} of equation~\eqref{eq:symmetric form}.
\end{definition}
\begin{remark}
    It should be noted that, strictly speaking, 
    equation~\eqref{eq:symmetric form} is not a differential equation. 
    However, expressing a first-order differential equation in the form of \eqref{eq:symmetric form} is extremely convenient for analysis.
    This formulation does not necessarily require $y$ to be expressed as a function of $x$. 
    For the sake of simplicity in description, we often refer to the symmetric form~\eqref{eq:symmetric form} as a differential equation, too.
\end{remark}

\begin{theorem}
    Let the functions \(M(x, y)\) and \(N(x, y)\) be continuous in a simply connected domain \(D \subset \mathbb{R}^2\), 
    and suppose their first-order partial derivatives \(\frac{\partial M}{\partial y}\) and \(\frac{\partial N}{\partial x}\) are also continuous. 
    Then a necessary and sufficient condition for equation~\eqref{eq:symmetric form} to be exact is
    \[
    \frac{\partial M}{\partial y} = \frac{\partial N}{\partial x}
    \]
    in the domain \(D\). 
    When this condition holds, for any \((x_0, y_0), (x, y) \in D\), a general integral of equation~\eqref{eq:symmetric form} is given by
    \[
    \int_{\gamma} M(x, y)dx + N(x, y)dy = c,
    \]
    where \(\gamma\) is any curve composed of finitely many smooth segments within \(D\) 
    connecting \((x_0, y_0)\) and \((x, y)\), and \(c\) is an arbitrary constant.
\end{theorem}
\begin{proof}
    Refer to \emph{Analyse Mathématique Thm 15.9}.
\end{proof}

The aforementioned proof also serves as a method for determining the bivariate function $U(x, y)$ 
that satisfies specific conditions. In addition to this approach, 
there exist two simpler methods for solving $U(x, y)$.

\begin{description}
    \item [Utilizing Curve Integrals to Solve $U(x, y)$] 

    \item [Term Combination Method]
        Utilizing the properties of bivariate differential functions, 
        we combine the terms of the differential equation into a full differential form. 
        This method requires familiarity with some simple bivariate differential functions, such as:
        \begin{gather*}
            y\mathrm{d}x + x\mathrm{d}y = \mathrm{d}(xy), \\
            \frac{y\mathrm{d}x-x\mathrm{d}y}{y^{2}} = \mathrm{d}\left(\frac{x}{y}\right), \\
            \frac{-y\mathrm{d}x+x\mathrm{d}y}{x^{2}} = \mathrm{d}\left(\frac{y}{x}\right), \\
            \frac{1}{x}\mathrm{d}x + \frac{1}{y}\mathrm{d}y = \frac{y\mathrm{d}x+x\mathrm{d}y}{xy} = \mathrm{d}(\ln |xy|), \\
            \frac{1}{x}\mathrm{d}x - \frac{1}{y}\mathrm{d}y = \frac{y\mathrm{d}x-x\mathrm{d}y}{xy} = \mathrm{d}(\ln |\frac{x}{y}|), \\
            \frac{y\mathrm{d}x-x\mathrm{d}y}{x^{2}-y^{2}} = \frac{1}{2}\mathrm{d}\left(\ln \left|\frac{x-y}{x+y}\right|\right), \\
            \frac{y\mathrm{d}x+x\mathrm{d}y}{x^{2}+y^{2}} = \mathrm{d}\left(\arctan \frac{y}{x}\right), \\
            \frac{y\mathrm{d}x-x\mathrm{d}y}{x^{2}+y^{2}} = \mathrm{d}\left( \operatorname{arccot} \frac{y}{x} \right).
        \end{gather*}
\end{description}


\vspace{0.7cm}
The theory above can also be rewritten in differential form:

Let:
\[
\omega^1 = M(x, y) \, \mathrm{d}x + N(x, y) \, \mathrm{d}y.
\]
The differential form \( \omega^1 \) is said to be \textbf{closed} if \( \mathrm{d}\omega^1 = 0 \). 
It is called \textbf{exact} if there exists a function \( U(x, y) \) such that \( \omega^1 = \mathrm{d}U(x, y) \). 
By the Poincaré theorem, it can be concluded that on \( \mathbb{R}^2 \), 
a first-order differential form is exact if and only if it is closed.
Note that:
\[
\mathrm{d}\omega^1 = \left( \frac{\partial N}{\partial x} - \frac{\partial M}{\partial y} \right) \mathrm{d}x \wedge \mathrm{d}y.
\]
Clearly, \( \mathrm{d}\omega^1 = 0 \) holds if and only if:
\[
\frac{\partial N}{\partial x} = \frac{\partial M}{\partial y}.
\]
Under this condition, the expression for the function \( U(x, y) \) is:
\[
U(x, y) = \int \omega^1.
\]


\section{Separable Equations}
\begin{definition}{Separable Equations}
    If the functions \(M(x, y)\) and \(N(x, y)\) in Equation~\eqref{eq:symmetric form} can both be written as 
    the product of a function of \(x\) and a function of \(y\), that is,
    \[
    M(x, y) = M_1(x) M_2(y), \quad N(x, y) = N_1(x) N_2(y),
    \]
    then equation~\eqref{eq:symmetric form} is called a separable equation.

    When equation~\eqref{eq:symmetric form} is a separable equation, it can be written as
    \begin{equation}\label{eq:separable form}
        M_1(x) M_2(y) \, \mathrm{d}x + N_1(x) N_2(y) \, \mathrm{d}y = 0,
    \end{equation}
    or more conveniently as
    \begin{equation}\label{eq:separable form 2}
        \frac{\mathrm{d}y}{\mathrm{d}x} = f(x)g(y) \left(= -\frac{M_1(x)}{N_1(x)} \cdot \frac{N_2(y)}{M_2(y)}\right).
    \end{equation}
\end{definition}

\begin{theorem}{Solutions to Separable Equations}\label{thm:solutions to separable equations}
    All the solutions to the separable equation~\eqref{eq:separable form} are given by:
    \[
    \int_{x_{0}}^{x}  \frac{M_{1}(t)}{N_{1}(t)}\mathrm{d}t + \int_{y_{0}}^{y} \frac{N_{2}(s)}{M_{2}(s)}\mathrm{d}s = c,
    \]
    and 
    \begin{gather*}
        y \equiv b_{i}, \quad i = 1, 2, \ldots, m, 
        x \equiv a_{j}, \quad j = 1, 2, \ldots, n,
    \end{gather*}
    where \(M_{2}(b_{i})=0\quad(i=1,2,\ldots,m)\) and \(N_{1}(a_{j})=0\quad(j=1,2,\ldots,n)\), \(c\) is arbitrary constant.
\end{theorem}


\section{Homogeneous Equations}
\begin{definition}{Homogeneous Functions}
    A function \(f(x, y)\) is called a \textbf{homogeneous function} of degree \(n\) 
    if it satisfies the condition:
    \[
    f(tx, ty) = t^n f(x, y)
    \]
    for all \(t > 0\).
    
    A function \(f(x, y)\) is called a \textbf{quasihomogeneous function} of degree \(d\) with generalized weights if
    \[
    f(t^\alpha s x, t^\beta s y) = t^{ds} f(x, y),
    \]
    where \(t > 0\), \(\alpha\) and \(\beta\) are positive constants with \(\alpha + \beta = 1\), and \(s \in \mathbb{R}\). 
    Here, \(\alpha\) and \(\beta\) are called the weights of \(x\) and \(y\), respectively.
\end{definition}


\begin{definition}\label{def:homogeneous equations}
    A first-order differential equation 
    \begin{equation*}
        M(x, y) \, \mathrm{d}x + N(x, y) \, \mathrm{d}y = 0
    \end{equation*}
    is called a \textbf{homogeneous equation} if both \(M\) and \(N\) are homogeneous functions
    of the same degree \(n\).    
    In other words, for the equation
    \[
        \frac{\mathrm{d}y}{\mathrm{d}x} = f(x, y), 
    \]
    \(f(x,y)\) can be rewritten as \(g\left(\frac{y}{x}\right)\).
\end{definition}


The equation  
\begin{equation}\label{eq:Second kind separable equation}
    \frac{dy}{dx} = f\left(\frac{a_1x + b_1y + c_1}{a_2x + b_2y + c_2}\right) 
\end{equation}
can be transformed into a separable equation via variable change, 
where \(a_1, a_2, b_1, b_2, c_1, c_2\) are constants. 

\begin{itemize}
    \item  When \(c_1 = c_2 = 0\), the equation becomes:  
        \[
        \frac{dy}{dx} = f\left(\frac{a_1 + b_1 \frac{y}{x}}{a_2 + b_2 \frac{y}{x}}\right) = g\left(\frac{y}{x}\right).
        \]
        Let
        \[
        u = \frac{y}{x}, \text{ namely } y = ux. 
        \]
        Differentiating both sides with respect to \(x\), we get:
        \[
        \frac{dy}{dx} = x \frac{du}{dx} + u.
        \]
        Substituting the results into original equation and simplifying, we obtain:
        \[
        \frac{du}{dx} = \frac{g(u) - u}{x},
        \]
        which is a separable equation. 
        It can be solved easily. 
        Then, substituting \(u = \frac{y}{x}\) back, the solution is derived.
    \item When \(c_1, c_2\) are not entirely zero, the right-hand side of ~\eqref{eq:Second kind separable equation} 
        consists of linear polynomials of \(x\) and \(y\). Therefore:
        \[
        \begin{cases}\label{eq gp:two lines}
        a_1x + b_1y + c_1 = 0, \\
        a_2x + b_2y + c_2 = 0,
        \end{cases}
        \]
        represents two intersecting straight lines on the \(Oxy\) plane. For the coefficient determinant of the system:
        \[
        \begin{vmatrix}
        a_1 & b_1 \\
        a_2 & b_2
        \end{vmatrix},
        \]
        two cases are analyzed:
        \begin{enumerate}
            \item  If \(\begin{vmatrix} a_1 & b_1 \\ a_2 & b_2 \end{vmatrix} \neq 0\), 
                then \(\frac{a_1}{a_2} \neq \frac{b_1}{b_2}\), 
                indicating that the two lines intersect at a unique point \((\alpha, \beta)\) on the \(Oxy\) plane. 
                Let:
                \[
                \begin{cases}
                X = x - \alpha, \\
                Y = y - \beta,
                \end{cases}
                \]
                then~\eqref{eq gp:two lines} becomes:
                \[
                \begin{cases}
                a_1X + b_1Y = 0, \\
                a_2X + b_2Y = 0.
                \end{cases}
                \]
                Substituting into~\ref{eq:Second kind separable equation}, it simplifies to:
                \[
                \frac{dY}{dX} 
                = f\left(\frac{a_1 + b_1 \frac{Y}{X}}{a_2 + b_2 \frac{Y}{X}}\right) 
                = g\left(\frac{Y}{X}\right).
                \]
                This is a homogeneous differential equation. 
                Solving it by substitution and reverting back to the original variables 
                yields the solution to equation~\ref{eq:Second kind separable equation}.
            \item When \(\begin{vmatrix} a_1 & b_1 \\ a_2 & b_2 \end{vmatrix} = 0\). 
                To ensure this system holds, there are three possible scenarios:
                \begin{enumerate}
                    \item  If \(a_1 = b_1 = 0\),~\ref{eq:Second kind separable equation} becomes:
                        \[
                        \frac{dy}{dx} = f\left(\frac{c_1}{a_2x + b_2y + c_2}\right),
                        \]
                        and when \(a_2 = b_2 = 0\), it becomes:
                        \[
                        \frac{dy}{dx} = f\left(\frac{a_1x + b_1y + c_1}{c_2}\right).
                        \]
                        In this case, 
                        let
                        \[
                        u = \frac{a_1x + b_1y + c_1}{c_2}.
                        \]
                        Then it can be transformed into a separable equation.
                    \item  If \(b_1 = b_2 = 0\), ~\ref{eq:Second kind separable equation} transforms into:
                        \[
                        \frac{dy}{dx} = f\left(\frac{a_1x + c_1}{a_2x + c_2}\right),
                        \]
                        and
                        \[
                        \frac{dy}{dx} = f\left(\frac{b_1y + c_1}{b_2y + c_2}\right),
                        \]
                        when \(a_1 = a_2 = 0\). 
                    \item If \(\frac{a_1}{a_2} = \frac{b_1}{b_2} = k\), let \(u = a_2x + b_2y\). In this case:
                        \begin{gather*}
                            \frac{du}{dx} = a_2 + b_2 \frac{\mathrm{d}y}{\mathrm{d}x} \\
                            f\left( \frac{k(a_2x + b_2y) + c_1}{(a_2x + b_2y) + c_2} \right) 
                                = f\left( \frac{ku + c_1}{u + c_2} \right) = g(u)
                        \end{gather*}
                        which simplifies to:
                        \[
                        \frac{du}{dx} = a_2 + b_2 g(u).
                        \]
                \end{enumerate}
        \end{enumerate}
\end{itemize}






\begin{example}
    Consider the differential equation
    \[
    M(x, y) \, \mathrm{d}x + N(x, y) \, \mathrm{d}y = 0,
    \]
    where \(M(x, y)\) and \(N(x, y)\) are quasihomogeneous functions of degree \(d_0\) and \(d_1\) 
    with weights \(\alpha\) and \(\beta\) for \(x\) and \(y\), respectively.
    \newline Proposition: When \(d_0 = d_1 + \beta - \alpha\) the equation can be solved by elementary integration method.
\end{example}


\section{Linear Equations}
\begin{definition}{First-Order Linear Equations}
    A \textbf{first-order linear equation} is an equation of the form
    \begin{equation}\label{eq:first order linear equation}
        \frac{\mathrm{d}y}{\mathrm{d}x} + p(x) y = q(x),
    \end{equation}
    where \(p(x)\) and \(q(x)\) are continuous functions on the interval \((a, b)\).
    In Equation~\eqref{eq:first order linear equation}, when \(q(x) \equiv  0\), we obtain
    \begin{equation}\label{eq:first order homogeneous linear equation}
        \frac{\mathrm{d}y}{\mathrm{d}x} + p(x) y = 0,
    \end{equation}
    which is called a \textbf{first-order homogeneous linear equation} corresponding to Equation~\eqref{eq:first order linear equation}.
    Otherwise, it is called a first-order non-homogeneous linear equation.
\end{definition}
\begin{note}
    It should be noted that the definition of a homogeneous equation here \emph{differs} from that in the previous section.
\end{note}

Firstly, we solve the first-order homogeneous linear equation.
Equation~\ref{eq:first order homogeneous linear equation} is separable, 
thus its general solution is given by:
\[
y = ce^{-\int p(x) \, \mathrm{d}x},
\]
where \(c\) is an arbitrary constant.

Since ~\ref{eq:first order homogeneous linear equation} is a special case of ~\ref{eq:first order linear equation},
the general solution of ~\ref{eq:first order linear equation} can be expressed as:
\[
y = c(x) e^{-\int p(x) \, \mathrm{d}x},
\]
substituting it into ~\ref{eq:first order linear equation} yields:
\[
y = e^{-\int p(x) \, \mathrm{d}x} \left( c + \int q(x) e^{\int p(x) \, \mathrm{d}x} \, \mathrm{d}x \right).
\]

This method of solving first-order linear equations is known as the \textbf{method of variation of constants}.

% 当有初值条件y(x_0)=y时, 解可以表示为:...
When an initial condition \(y(x_0) = y_0\) is provided, the solution can be expressed as:
\[
y = e^{-\int_{x_0}^{x} p(t) \, \mathrm{d}t} \left( y_0 + \int_{x_0}^{x} q(t) e^{\int_{x_0}^{t} p(s) \, \mathrm{d}s} \, \mathrm{d}t \right)
= e^{-\int_{x_0}^{x} p(t) \, \mathrm{d}t} y_0 + \int_{x_0}^{x} q(t) e^{-\int_{t}^{x} p(s) \, \mathrm{d}s} \, \mathrm{d}t.
\]
% 最后一个式子可以记作: "基本解*初值加上基本解与非齐次项的卷积"
The last expression can be interpreted as the 
\newline``\emph{fundamental solution \(\times \) the initial value \(+\) 
the convolution of the fundamental solution with the non-homogeneous term}."

\begin{remark}
    % 常数变易法推广到非齐次线性偏微分方程中, 称为"Duhamel原理".
    The method of variation of constants can be extended to non-homogeneous linear partial differential equations, 
    known as the ''Duhamel's principle''.
\end{remark}

\begin{definition}{Bernoulli's Equation}
    A first-order differential equation of the form
    \begin{equation*}
        \frac{\mathrm{d}y}{\mathrm{d}x} + p(x) y = q(x) y^n,\quad n \neq 0, 1,
    \end{equation*}
    where \(n\) is a real number and \(p(x)\) and \(q(x)\) are continuous functions on the interval \((a, b)\), 
    is called a \textbf{Bernoulli's equation}.
\end{definition}
Bernoulli's equation can be transformed into a first-order linear equation by the substitution:
\[z = y^{1-n}.\]
Differentiating both sides with respect to \(x\) gives:
\[\frac{\mathrm{d}z}{\mathrm{d}x} = (1-n) y^{-n} \frac{\mathrm{d}y}{\mathrm{d}x}.\]
Substituting \(\frac{\mathrm{d}y}{\mathrm{d}x}\) from Bernoulli's equation into the above expression yields:
\[\frac{\mathrm{d}z}{\mathrm{d}x} = (1-n) \left( -p(x) z + q(x) \right).\]
This is a first-order linear equation in \(z\), which can be solved using the method for first-order linear equations.

\vspace{0.7cm}
\begin{example}
    \(f\in C[0,+\infty), \lim_{x \to \infty}f(x)=b\).
    Prove: For the equation
    \[
    \frac{\mathrm{d}y}{\mathrm{d}x} + ay = f(x),
    \]
    when \(a > 0\), any solution \(y(x)\) satisfies \(\lim_{x \to \infty} y(x) = \frac{b}{a}\);
    when \(a < 0\), there exists a unique solution \(y(x)\) such that \(\lim_{x \to \infty} y(x) = \frac{b}{a}\).
\end{example}

\begin{proof}
    
\end{proof}

\section{Integrating Factors}
\begin{definition}{Integrating Factors}
    % 对于非恰当微分形式omega, 若存在一个非零可微函数mu, 使得mu*omega是恰当微分形式, 则称mu为omega的积分因子.
    For a non-exact differential form \(\omega = M(x, y) \, \mathrm{d}x + N(x, y) \, \mathrm{d}y\),
    if there exists a non-zero differentiable function \(\mu(x, y)\) such that \(\mu(x, y) \omega\) is an exact differential form,
    then \(\mu(x, y)\) is called an \textbf{integrating factor} of \(\omega\).
    % 
    Id est, there exists a function \(\Phi(x, y)\) such that
    \[
    \mu(x, y) \omega = \mathrm{d}U(x, y).
    \]
    If such functions \(\mu(x, y)\) and \(U(x, y)\) exist, and \(U(x, y)\) is smooth, then
    \begin{equation}\label{eq:integrating factor condition}
        \frac{\partial(\mu M)}{\partial y} = \frac{\partial(\mu N)}{\partial x}
        \left( = \frac{\partial^2 U}{\partial x \partial y} \right).
    \end{equation}
\end{definition}
According to Equation~\eqref{eq:integrating factor condition}, 
finding an integrating factor \(\mu(x, y)\) for \(\omega\)
is equivalent to solving the partial differential equation:
\begin{equation}\label{eq:integrating factor PDE}
    \frac{\partial \mu}{\partial x} N - \frac{\partial \mu}{\partial y} M 
    = \left( \frac{\partial M}{\partial y} - \frac{\partial N}{\partial x} \right) \mu.
\end{equation}

\begin{theorem}
\begin{enumerate}
    \item For the partial differential equation~\ref{eq:integrating factor PDE} 
        to have a solution $\mu(x)$ that depends only on $x$, the necessary and sufficient condition is:

        The function $G$ defined below must depend only on $x$:
        \[
        G = -\frac{1}{N(x, y)}\left( \frac{\partial N}{\partial x} - \frac{\partial M}{\partial y} \right) .
        \]

        In this case, we have:
        \[
        \mu(x) = e^{\int_{x_0}^{x} G(t) \, dt}.
        \]
    
    \item 
        For the partial differential equation~\ref{eq:integrating factor PDE} 
        to have a solution $\mu(y)$ that depends only on $y$, 
        the necessary and sufficient condition is:

        The function $H$ defined below must depend only on $y$:
        \[
        H = \frac{1}{M(x, y)}\left( \frac{\partial N}{\partial x} - \frac{\partial M}{\partial y} \right) .
        \]

        In this case, we have:
        \[
        \mu(y) = e^{\int_{y_0}^{y} H(s) \, ds}.
        \]

    \item 
        For \(\omega\) to have an integrating factor of the form 
        $\mu = \mu(\phi(x, y))$, the necessary condition is:
        \[
        \frac{1}{\frac{\partial \phi}{\partial x} N - \frac{\partial \phi}{\partial y} M} 
        \left( \frac{\partial M}{\partial y} - \frac{\partial N}{\partial x} \right) 
        = f(\phi(x, y)),
        \]
        where \(f\) is a certain univariate function.
\end{enumerate}
\end{theorem}


\begin{theorem}
    Let the functions \(P(x, y)\), \(Q(x, y)\), \(\mu_1(x, y)\), and \(\mu_2(x, y)\) be continuously differentiable. 
    Suppose \(\mu_1(x, y)\) and \(\mu_2(x, y)\) are integrating factors for \(\omega\), 
    and the ratio \(\frac{\mu_1(x, y)}{\mu_2(x, y)}\) is not a constant. 
    Then: 
    \[
    \frac{\mu_1(x, y)}{\mu_2(x, y)} = c
    \]
    is a general solution to the equation, where \(c\) is an arbitrary constant.
\end{theorem}


\section{Implicit Equations}
This section discusses the problem of solving the first-order implicit differential equations,
\begin{equation}\label{eq:implicit ODE}
F(x, y, y') = 0
\end{equation}
where \(F\) is a continuously differentiable function. 

Denote \(p=y'=\frac{\mathrm{d}y}{\mathrm{d}x}\),
\begin{enumerate}[label=(\alph*)]
    \item If \(p\) is solvable, i.e., \(p = f(x, y)\), 
        then equation~\eqref{eq:implicit ODE} becomes a first-order explicit differential equation,
        which can be solved using the methods discussed in previous sections. 
    \item If \(y\) is solvable, i.e., \(y = f(x, p)\), 
        then differentiating both sides with respect to \(x\) gives:
        \[
        \frac{\mathrm{d}y}{\mathrm{d}x} = p = \frac{\partial f}{\partial x} + \frac{\partial f}{\partial p} \frac{\mathrm{d}p}{\mathrm{d}x}.
        \]
        Rearranging yields:
        \[
        \frac{\mathrm{d}p}{\mathrm{d}x} = \frac{p - \frac{\partial f}{\partial x}}{\frac{\partial f}{\partial p}}.
        \]
        This is a first-order differential equation in \(p\), which can be solved using the methods discussed earlier. 
        After finding \(p(x)\), substituting back into \(y = f(x, p)\) gives the solution for \(y\).
    \item If \(x\) is solvable, i.e., \(x = f(y, p)\), 
        then differentiating both sides with respect to \(x\) gives:
        \[
        1 = \frac{\partial f}{\partial y} \frac{\mathrm{d}y}{\mathrm{d}x} + \frac{\partial f}{\partial p} \frac{\mathrm{d}p}{\mathrm{d}x}.
        \]
        Rearranging yields:
        \[
        \frac{\mathrm{d}p}{\mathrm{d}x} = \frac{1 - p \frac{\partial f}{\partial y}}{\frac{\partial f}{\partial p}}.
        \]
        This is a first-order differential equation in \(p\), which can be solved using the methods discussed earlier. 
        After finding \(p(x)\), substituting back into \(x = f(y, p)\) gives the solution for \(y\).
    \item If none of the above three cases apply, 
        one can attempt to solve equation~\eqref{eq:implicit ODE} using the method of parameterization.
        Let \(x=\varphi(u, v), y=\psi(u, v), p=\theta(u, v)\).
        By \(\mathrm{d}y = p \, \mathrm{d}x\), we have:
        \[
        \frac{\partial \psi}{\partial u} \, \mathrm{d}u + \frac{\partial \psi}{\partial v} \, \mathrm{d}v
        = \theta \left( \frac{\partial \varphi}{\partial u} \, \mathrm{d}u + 
        \frac{\partial \varphi}{\partial v} \, \mathrm{d}v \right).
        \]
\end{enumerate}

\vspace{0.7cm}
% 形如xxx格式的叫做克莱罗方程
Equations of the form
\[
    y = x p + g(p)
\]
are called \textbf{Clairaut's equations}, where \(p = y', g(p)\in C^{1}\).
\newline Differentiating both sides with respect to \(x\) gives:
\[
    p = p + x \frac{\mathrm{d}p}{\mathrm{d}x} + g'(p) \frac{\mathrm{d}p}{\mathrm{d}x}.
\]
Rearranging yields:
\[
    \left( x + g'(p) \right) \frac{\mathrm{d}p}{\mathrm{d}x} = 0.
\]
Thus, there are two cases to consider:
\begin{enumerate}
    \item When \(\frac{\mathrm{d}p}{\mathrm{d}x} = 0\), \(p\) is a constant, denoted as \(c\). 
        Substituting back into the original equation gives the general solution:
        \[
        y = cx + g(c).
        \]
    \item When \(x + g'(p) = 0\), solving for \(x\) gives:
        \[
        x = -g'(p).
        \]
        Substituting back into the original equation yields the singular solution:
        \[
        y = -p g'(p) + g(p).
        \]
        This represents a parametric curve in the \(Oxy\) plane, with parameter \(p\).
\end{enumerate}

% Clairaut 方程可以推广到更一般的形式, 即Lagrange方程
Clairaut's equations can be generalized to a more general form known as \textbf{Lagrange's equations}:
\[
    y = x f(p) + g(p),
\]
where \(p = y', f(p), g(p) \in C^{1}\).
\newline Differentiating both sides with respect to \(x\) gives:
\[
    p = f(p) + x f'(p) \frac{\mathrm{d}p}{\mathrm{d}x} + g'(p) \frac{\mathrm{d}p}{\mathrm{d}x}.
\]
Rearranging yields:
\[
    \left( x f'(p) + g'(p) \right) \frac{\mathrm{d}p}{\mathrm{d}x} = p - f(p).
\]
Thus, there are two cases to consider:
\begin{enumerate}
    \item When \(p - f(p) = 0\), solving for \(p\) gives \(p = c\). 
        Substituting back into the original equation gives the general solution:
        \[
        y = cx + g(c).
        \]
    \item When \(x f'(p) + g'(p) = 0\), solving for \(x\) gives:
        \[
        x = -\frac{g'(p)}{f'(p)}.
        \]
        Substituting back into the original equation yields the singular solution:
        \[
        y = -\frac{g'(p)}{f'(p)} f(p) + g(p).
        \]
        This represents a parametric curve in the \(Oxy\) plane, with parameter \(p\).
\end{enumerate}

\section{Higher-Order Equations Reducible to Lower Order} % 可降阶的高阶方程
Some higher-order differential equations can be reduced to lower-order equations through variable substitution.
\begin{enumerate}
    \item If a differential equation of order \(n\) does not explicitly contain the dependent variable \(y\) and 
        its lower-order derivatives up to \(y^{(k-1)}\), i.e., it can be expressed as:
        \[
        F\left( x, y^{(k)}, y^{(k+1)}, \ldots, y^{(n)} \right) = 0,
        \]
        then by letting \(p = y^{(k)}\), we have:
        \[
        y^{(k+1)} = p \frac{\mathrm{d}p}{\mathrm{d}y^{(k)}}, \quad y^{(k+2)} = 
        p^2 \frac{\mathrm{d}^2 p}{\mathrm{d}(y^{(k)})^2} + p \left( \frac{\mathrm{d}p}{\mathrm{d}y^{(k)}} \right)^2,
        \]
        and so on. 
        Substituting these expressions into the original equation reduces it to an equation of order \(n-1\) in terms of \(p\) and \(y\).
    \item If a differential equation of order \(n\) does not explicitly contain the independent variable \(x\), 
        i.e., it can be expressed as:
        \[
        F\left( y, y', y'', \ldots, y^{(n)} \right) = 0,
        \]
        then by letting \(p = y'\), we have:
        \[
        y'' = p \frac{\mathrm{d}p}{\mathrm{d}y}, \quad y''' = p^2 \frac{\mathrm{d}^2 p}{\mathrm{d}y^2} + p \left( \frac{\mathrm{d}p}{\mathrm{d}y} \right)^2,
        \]
        and so on. 
        Substituting these expressions into the original equation reduces it to an equation of order \(n-1\) in terms of \(p\) and \(y\).
    \item If a differential equation of order \(n\) does not explicitly contain certain derivatives,
        i.e., it can be expressed as:
        \[
        F\left( x, y, y', \ldots, y^{(k-1)}, y^{(k+1)}, \ldots, y^{(n)} \right) = 0,
        \]
        then by letting \(p = y^{(k)}\), we have:
        \[
        y^{(k+1)} = p \frac{\mathrm{d}p}{\mathrm{d}y^{(k-1)}}, \quad y^{(k+2)} = p^2 \frac{\mathrm{d}^2 p}{\mathrm{d}(y^{(k-1)})^2} + p \left( \frac{\mathrm{d}p}{\mathrm{d}y^{(k-1)}} \right)^2,
        \]
        and so on. 
        Substituting these expressions into the original equation reduces it to an equation of order \(n-1\) in terms of \(p\) and \(y^{(k-1)}\).
\end{enumerate}

% 形如xxx的高阶方程称为欧拉柯西方程
Differential equations of the form:
\[
    x^n y^{(n)} + a_{n-1} x^{n-1} y^{(n-1)} + \cdots + a_1 x y' + a_0 y = f(x),
\]
where \(a_0, a_1, \ldots, a_{n-1}\) are constants, are called \textbf{Euler-Cauchy equations}.
\newline By letting \(x = e^t\), we have:
\[
    \frac{\mathrm{d}y}{\mathrm{d}x} = \frac{1}{x} \frac{\mathrm{d}y}{\mathrm{d}t}, \quad
    \frac{\mathrm{d}^2 y}{\mathrm{d}x^2} = \frac{1}{x^2} \left( \frac{\mathrm{d}^2 y}{\mathrm{d}t^2} 
    - \frac{\mathrm{d}y}{\mathrm{d}t} \right), \quad
    \ldots, \quad
    \frac{\mathrm{d}^n y}{\mathrm{d}x^n} = \frac{1}{x^n} \left( \frac{\mathrm{d}^n y}{\mathrm{d}t^n} 
    - (n-1) \frac{\mathrm{d}^{n-1} y}{\mathrm{d}t^{n-1}} + \cdots + (-1)^{n-1} \frac{\mathrm{d}y}{\mathrm{d}t} \right).
\]
Substituting these expressions into the original equation transforms it into a linear differential equation 
with constant coefficients in terms of \(t\).
% 另一种解法是先用特征根法求齐次通解, 再用常数变易法求非齐次特解.
\newline Another method is to first find the general solution of the homogeneous equation using the characteristic root method,
and then use the method of variation of constants to find a particular solution of the non-homogeneous equation. 

\vspace{0.7cm}
\begin{example}
    Fill in the blanks:
    \begin{enumerate}
        \item Equation 
            \[
            y\ln y \mathrm{d}x + (x-\ln y) \mathrm{d}y = 0
            \]
            is which type of equation? ()
        \item Equation  
            \[
            \frac{\mathrm{d}y}{\mathrm{d}x} = \sqrt{y},\quad (0\leqslant y\leqslant +\infty)
            \]
            has how many solutions passing through the point \((0,0)\)? ()
        \item All constants solutions of the equation 
            \[
            x(y^{2}-1) \mathrm{d}x + y(x^{2}-1) \mathrm{d}y = 0
            \]
            are: ()
    \end{enumerate}
\end{example}

\begin{solution}
\begin{enumerate}
    \item Linear equation. 
        \newline Rewriting the equation gives:
        \[
        \frac{\mathrm{d}x}{\mathrm{d}y} = \frac{1}{y\ln y}x-\frac{1}{y},
        \]
        which is a first-order linear equation.
    \item Infinite solutions. 
        % 由于解不满足唯一性要求, 因此可以构造分段形式的解.
        \newline Since the solution does not satisfy the uniqueness requirement,
        piecewise solutions can be constructed.
        For example:
        \[
        y = \begin{cases}
        0, & x \in [0, 2], \\
        \frac{x^2}{4}, & x > 2.
        \end{cases}
        \]
    \item \(y=\pm 1, x=\pm 1\).
        \newline By Theorem~\ref{thm:solutions to separable equations},
        let
        \[
        M_{1}(x)=x, \quad M_{2}(y)=y^{2}-1, \quad N_{1}(x)=x^{2}-1, \quad N_{2}(y)=y,
        \]
        then the constant solutions are:
        \[
        M_{2}(y)=0 \Rightarrow y=\pm 1, \quad N_{1}(x)=0 \Rightarrow x=\pm 1.
        \]
\end{enumerate}
\end{solution}

\begin{caution}
    % 注意, 当方程写成对称形式时, x 和 y 的角色是对等的.
    Note that when an equation is written in symmetric form,
    the roles of \(x\) and \(y\) are interchangeable.
\end{caution}
